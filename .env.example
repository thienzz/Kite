# Kite Framework Configuration Template
# Copy this file to .env and fill in your values

# ============================================================================
# LLM Provider Configuration
# ============================================================================
# Main Model (Reasoning/Complex Tasks)
# Options: ollama, groq, openai, anthropic, gemini, together, vllm, lmstudio, mistral
LLM_PROVIDER=ollama
LLM_MODEL=llama3.1

# Fast Model (Routing/Planning/Simple Tasks) - Optional
# Recommended: groq/llama-3.1-8b-instant or ollama/qwen2.5:0.5b
FAST_LLM_MODEL=groq/llama-3.1-8b-instant

# Smart Model (Complex Reasoning/Analysis) - Optional
# Recommended: groq/llama-3.3-70b-versatile or openai/gpt-4
SMART_LLM_MODEL=groq/llama-3.3-70b-versatile

# Base URL for local providers (Ollama default: http://localhost:11434)
# LLM_BASE_URL=http://localhost:11434

# ============================================================================
# API Keys (Fill in as needed for your provider)
# ============================================================================
GROQ_API_KEY=your_groq_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
GEMINI_API_KEY=your_gemini_api_key_here
TOGETHER_API_KEY=your_together_api_key_here
MISTRAL_API_KEY=your_mistral_api_key_here

# ============================================================================
# Semantic Router & Routing
# ============================================================================
# Options: llm, embedding
ROUTER_TYPE=llm

# If using explicit router model (overrides FAST_LLM_MODEL)
# ROUTER_LLM_PROVIDER=groq
# ROUTER_LLM_MODEL=llama-3.1-8b-instant

# Minimum confidence threshold for routing (0.0 to 1.0)
SEMANTIC_ROUTER_THRESHOLD=0.15

# ============================================================================
# Embedding Configuration
# ============================================================================
# Options: sentence-transformers, openai, ollama, gemini
EMBEDDING_PROVIDER=sentence-transformers
# Model name (e.g., all-MiniLM-L6-v2, text-embedding-3-small)
EMBEDDING_MODEL=all-MiniLM-L6-v2

# ============================================================================
# Safety & Reliability
# ============================================================================
CIRCUIT_BREAKER_FAILURE_THRESHOLD=3
CIRCUIT_BREAKER_TIMEOUT_SECONDS=60
# Global timeout for LLM calls in seconds
LLM_TIMEOUT=60.0

# ============================================================================
# Memory & Storage
# ============================================================================
# Options: memory, chroma, pinecone, qdrant
VECTOR_BACKEND=memory
# DB Connection string if using persistent storage
# DATABASE_URL=postgresql://user:password@localhost:5432/kite

# ============================================================================
# Tool / MCP Configuration (Optional)
# ============================================================================
SLACK_WORKSPACE=demo
# SLACK_BOT_TOKEN=xoxb-...
# GMAIL_CLIENT_ID=...
# STRIPE_API_KEY=sk_test_...
