import asyncio
import os
from kite.core import Kite

async def test_reflection_agent():
    print("Testing ReflectiveAgent...")
    ai = Kite(config={
        'llm_provider': 'mock', # Using mock to avoid API costs during test structure verification
        'llm_model': 'mock-gpt4',
        'max_iterations': 5
    })
    
    # We need to mock the LLM responses to simulate the critique loop effectively
    # Since we can't easily mock the internal LLM object without more complex patching,
    # we'll do a structural test first to ensure the loop logic works.
    
    # However, to see it "in action" with real logic, let's use a real provider if available
    # or fallback to a simple mock that returns predictable strings.
    
    if os.getenv("OPENAI_API_KEY") or os.getenv("GROQ_API_KEY"):
         # Use real LLM if keys are present (preferred for behavior testing)
        ai = Kite() 
        print("Using REAL LLM for test.")
    else:
        print("Using MOCK LLM (behavior may be limited).")
        # Creating a custom mock LLM for this test
        class MockLLM:
            def __init__(self): self.chat_history = []
            def chat(self, messages, **kwargs):
                last_msg = messages[-1]['content']
                if "Original Request" in last_msg: # Critique phase
                    return "Critique: The response is missing the explanation of WHY."
                elif "Critique:" in last_msg: # Refine phase
                    return "Refined Response: Here is the answer with the explanation of WHY."
                else: # Initial generation
                    return "Initial Response: Here is the answer."
            def complete(self, prompt, **kwargs): return "Completed"
            
        ai._llm = MockLLM()

    # Create the reflective agent
    agent = ai.create_reflective_agent(
        name="Reflector",
        system_prompt="You are a helpful assistant.",
        critic_prompt="You are a critic. If the response is short, say 'Make it longer'. If it's long enough, say 'PERFECT'.",
        max_reflections=2
    )
    
    print("\n--- Running Agent ---")
    result = await agent.run("Explain quantum entanglement briefly.")
    
    print("\n--- Result ---")
    print(f"Success: {result['success']}")
    print(f"Final Response: {result['response']}")
    
    # Verify history contains reflection steps
    history_str = str(result['history'])
    
    # In a real run, we'd expect logs indicating critique and refinement.
    # Since we can't easily assert on logs here without capturing stderr,
    # we'll rely on the output and the manual verification of the loop execution logic via the mock 
    # or the side effects in a real run.
    
    print("\nðŸŽ‰ Test Finished. (Check logs above for 'Reflection cycle' messages)")

if __name__ == "__main__":
    asyncio.run(test_reflection_agent())
